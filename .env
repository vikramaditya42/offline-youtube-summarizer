# App Settings
PROJECT_NAME="Offline YT Summarizer"
VERSION="1.0.0"
API_PREFIX="/api/v1"

# Compute Settings
# Options: "cpu", "cuda" (for NVIDIA), "mps" (for Mac M-series)
DEVICE_TYPE="cpu" 

# Paths (Relative to project root)
TEMP_DIR="temp"
MODEL_DIR="models"

# Model Configuration
# WHISPER_MODEL options: tiny, base, small, medium, large-v3
WHISPER_MODEL_SIZE="base" 
WHISPER_COMPUTE_TYPE="int8" # "float16" if using GPU

# Summarization Model (Filename in the models/ directory)
LLM_MODEL_FILE="llama-3.2-3b-instruct-q4_k_m.gguf"
# Context window (match the model's capacity, e.g., 2048, 8192)
LLM_CONTEXT_WINDOW=4096